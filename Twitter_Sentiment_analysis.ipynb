{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4518e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-autotime in c:\\users\\duong\\anaconda3\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: ipython in c:\\users\\duong\\anaconda3\\lib\\site-packages (from ipython-autotime) (8.12.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\duong\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\duong\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\duong\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\duong\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\duong\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\duong\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\duong\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\duong\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\duong\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (5.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\duong\\anaconda3\\lib\\site-packages (from ipython->ipython-autotime) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\duong\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\duong\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->ipython-autotime) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\duong\\anaconda3\\lib\\site-packages (from stack-data->ipython->ipython-autotime) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\duong\\anaconda3\\lib\\site-packages (from stack-data->ipython->ipython-autotime) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\duong\\anaconda3\\lib\\site-packages (from stack-data->ipython->ipython-autotime) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\duong\\anaconda3\\lib\\site-packages (from asttokens->stack-data->ipython->ipython-autotime) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a1ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764f1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"twitter_training.csv\")\n",
    "train_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43f9035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2401\n",
      "Borderlands\n",
      "Positive\n",
      "im getting on borderlands and i will murder you all ,\n"
     ]
    }
   ],
   "source": [
    "for col in train_data.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df973c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.rename(columns={2401:'id','Borderlands':'name','Positive':'sentiment','im getting on borderlands and i will murder you all ,':'text'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b09672",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'Positive': 1,\n",
    "    'Negative': 0,\n",
    "    'Neutral': 2,\n",
    "    'Irrelevant': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cbcbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['sentiment_label'] = [mapping[value] for value in train_data['sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f9d7ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73995 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text  \\\n",
       "0      Positive  I am coming to the borders and I will kill you...   \n",
       "1      Positive  im getting on borderlands and i will kill you ...   \n",
       "2      Positive  im coming on borderlands and i will murder you...   \n",
       "3      Positive  im getting on borderlands 2 and i will murder ...   \n",
       "4      Positive  im getting into borderlands and i can murder y...   \n",
       "...         ...                                                ...   \n",
       "74676  Positive  Just realized that the Windows partition of my...   \n",
       "74677  Positive  Just realized that my Mac window partition is ...   \n",
       "74678  Positive  Just realized the windows partition of my Mac ...   \n",
       "74679  Positive  Just realized between the windows partition of...   \n",
       "74680  Positive  Just like the windows partition of my Mac is l...   \n",
       "\n",
       "       sentiment_label  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "...                ...  \n",
       "74676                1  \n",
       "74677                1  \n",
       "74678                1  \n",
       "74679                1  \n",
       "74680                1  \n",
       "\n",
       "[73995 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.drop(['2401','name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7237a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\duong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\duong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\duong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\duong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import nltk \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\" # Return an empty string for non-string values\n",
    "    text=re.sub('<[^>]*>','',text)\n",
    "    text=re.sub('[^a-zA-Z]',' ',text).lower()\n",
    "    words = word_tokenize(text)\n",
    "    stop_words= set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    preprocessed_text = ' '.join(words)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c17f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['preprocessed_text']=train_data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e60be2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2401                 12447\n",
       "name                    32\n",
       "sentiment                4\n",
       "text                 69490\n",
       "sentiment_label          4\n",
       "preprocessed_text    59828\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cceb5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(train_data['preprocessed_text'],train_data['sentiment_label'],test_size=0.2,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4038f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy in COUNT is :  86.5 %\n",
      "Prediction accuracy in tfidf is :  92.2 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim.models import Word2Vec\n",
    "vectorizer1=CountVectorizer()\n",
    "vectorizer2=TfidfVectorizer()\n",
    "X_train_count=vectorizer1.fit_transform(X_train)\n",
    "X_test_count=vectorizer1.transform(X_test)\n",
    "X_train_tfidf=vectorizer2.fit_transform(X_train)\n",
    "X_test_tfidf=vectorizer2.transform(X_test)\n",
    "clf1=SVC()\n",
    "clf1.fit(X_train_count,y_train)\n",
    "y_predict_count=clf1.predict(X_test_count)\n",
    "accuracy_count=accuracy_score(y_test,y_predict_count)\n",
    "print(\"Prediction accuracy in COUNT is : \",round(accuracy_count,3)*100,'%')\n",
    "clf2 = SVC()\n",
    "clf2.fit(X_train_tfidf, y_train)\n",
    "y_predict_tfidf = clf2.predict(X_test_tfidf)\n",
    "accuracy_tfidf=accuracy_score(y_test,y_predict_tfidf)\n",
    "print(\"Prediction accuracy in tfidf is : \",round(accuracy_tfidf,3)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d195e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=\"During Mohammed Azharuddin's time, even Zimbabwe seemed tough for India. Then MK Dhoni came and we started defeating Australia. And we because the world champions. When Manmohan Singh was the PM, even Pakistan seemed powerful. Today, after Modi's arrival we find China to be a lightweight. What's important is who is your captain.\"\n",
    "t=preprocess_text(t)\n",
    "t=[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "633d523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=vectorizer2.transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "831323bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "pred1 = clf2.predict(t2)\n",
    "if pred1 == 0:\n",
    "    print('Negative')\n",
    "elif pred1 == 1:\n",
    "    print('Positive')\n",
    "elif pred1 == 2:\n",
    "    print('Neutral')\n",
    "else:\n",
    "    print('Irrelevant')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
